#!/usr/bin/env python3
"""
í•œêµ­ì–´ ìŒì„± ë°ì´í„°ë¥¼ HuggingFaceì— ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œ
ê°„ë‹¨í•œ íë¦„: ì½ê¸° â†’ ì²˜ë¦¬ â†’ í‘¸ì‹œ â†’ ì‚­ì œ â†’ ë°˜ë³µ
"""

import os
import json
import zipfile
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Tuple
import pandas as pd
from datasets import Dataset, DatasetDict, Audio, Features, Value, concatenate_datasets
from huggingface_hub import HfApi, create_repo
import argparse
from tqdm import tqdm
import gc

class KoreanSpeechBatchUploader:
    def __init__(self, repo_id: str, token: str = None):
        self.repo_id = repo_id
        self.api = HfApi(token=token)
        
        # Features ì •ì˜
        self.features = Features({
            'audio': Audio(sampling_rate=44100),
            'text': Value('string'),
            'gender': Value('string'),
            'age': Value('string'),
            'dialect': Value('string'),
            'category': Value('string'),
            'subcategory': Value('string'),
            'dialog_id': Value('string'),
            'word_type': Value('string'),
            'word_define': Value('string'),
        })
        
        # ì €ì¥ì†Œ ìƒì„±
        try:
            create_repo(self.repo_id, repo_type="dataset", private=True, exist_ok=True, token=self.api.token)
        except Exception as e:
            print(f"ì €ì¥ì†Œ ìƒì„±/í™•ì¸: {e}")
        
        self.first_push = {'train': True, 'validation': True}
    
    def process_batch(self, batch_pairs: List[Tuple[str, str]], split_name: str, batch_num: int, total_batches: int):
        """
        ë°°ì¹˜ ì²˜ë¦¬: ZIP ì½ê¸° â†’ ì²˜ë¦¬ â†’ í‘¸ì‹œ â†’ ì„ì‹œíŒŒì¼ ì‚­ì œ
        """
        print(f"\nğŸ“¦ ë°°ì¹˜ [{batch_num}/{total_batches}] ì²˜ë¦¬ ì‹œì‘...")
        
        # 1. ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp(prefix=f"korean_speech_{split_name}_")
        
        try:
            all_data = []
            
            # 2. ë°°ì¹˜ ë‚´ ëª¨ë“  ZIP íŒŒì¼ ì²˜ë¦¬
            for i, (source_zip, label_zip) in enumerate(batch_pairs, 1):
                print(f"  íŒŒì¼ {i}/{len(batch_pairs)}: {os.path.basename(source_zip)}")
                
                # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
                filename = os.path.basename(source_zip).replace('.zip', '')
                for prefix in ['VS_', 'VL_', 'TS_', 'TL_']:
                    filename = filename.replace(prefix, '')
                
                audio_dir = os.path.join(temp_dir, filename, 'audio')
                label_dir = os.path.join(temp_dir, filename, 'label')
                os.makedirs(audio_dir, exist_ok=True)
                os.makedirs(label_dir, exist_ok=True)
                
                # ì›ì²œë°ì´í„°(ì˜¤ë””ì˜¤) ì••ì¶• í•´ì œ
                with zipfile.ZipFile(source_zip, 'r') as zip_ref:
                    for member in zip_ref.namelist():
                        if member.endswith('.wav'):
                            filename_only = os.path.basename(member)
                            target_path = os.path.join(audio_dir, filename_only)
                            source = zip_ref.open(member)
                            with open(target_path, 'wb') as target:
                                shutil.copyfileobj(source, target)
                
                # ë¼ë²¨ë§ë°ì´í„°(JSON) ì••ì¶• í•´ì œ
                with zipfile.ZipFile(label_zip, 'r') as zip_ref:
                    for member in zip_ref.namelist():
                        if member.endswith('.json'):
                            filename_only = os.path.basename(member)
                            target_path = os.path.join(label_dir, filename_only)
                            source = zip_ref.open(member)
                            with open(target_path, 'wb') as target:
                                shutil.copyfileobj(source, target)
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ ë§µí•‘
                audio_files = {}
                for file in os.listdir(audio_dir):
                    if file.endswith('.wav'):
                        file_id = file.replace('.wav', '')
                        audio_files[file_id] = os.path.join(audio_dir, file)
                
                # JSONê³¼ ë§¤ì¹­í•˜ì—¬ ë°ì´í„° ìƒì„±
                for file in os.listdir(label_dir):
                    if file.endswith('.json'):
                        file_id = file.replace('.json', '')
                        json_path = os.path.join(label_dir, file)
                        
                        try:
                            with open(json_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            
                            if file_id in audio_files:
                                record = {
                                    'audio': audio_files[file_id],
                                    'dialog_id': data.get('DialogID', ''),
                                    'category': data.get('Category', ''),
                                    'subcategory': data.get('SubCategory', ''),
                                    'text': '',
                                    'gender': '',
                                    'age': '',
                                    'dialect': '',
                                    'word_type': '',
                                    'word_define': ''
                                }
                                
                                # í™”ì ì •ë³´
                                speakers = data.get('Speakers', [])
                                if speakers:
                                    speaker = speakers[0]
                                    record['gender'] = speaker.get('Gender', '')
                                    record['age'] = speaker.get('AgeGroup', '')
                                    record['dialect'] = speaker.get('Locate', '')
                                
                                # ëŒ€í™” ì •ë³´
                                dialogs = data.get('Dialogs', [])
                                if dialogs:
                                    dialog = dialogs[0]
                                    record['text'] = dialog.get('SpeakerText', '')
                                    
                                    words = dialog.get('WordInfo', [])
                                    if words:
                                        word_info = words[0]
                                        record['word_type'] = word_info.get('WordType', '')
                                        record['word_define'] = word_info.get('WordDefine', '')
                                
                                all_data.append(record)
                        
                        except Exception as e:
                            print(f"    JSON ì˜¤ë¥˜ ({file}): {e}")
            
            # 3. Dataset ìƒì„± ë° í‘¸ì‹œ
            if all_data:
                print(f"  ë°ì´í„°ì…‹ ìƒì„± ì¤‘... ({len(all_data)}ê°œ ìƒ˜í”Œ)")
                df = pd.DataFrame(all_data)
                dataset = Dataset.from_pandas(df, features=self.features)
                
                print(f"  ğŸ“¤ HuggingFaceì— í‘¸ì‹œ ì¤‘...")
                dataset_dict = DatasetDict({split_name: dataset})
                
                # ì²« ë²ˆì§¸ í‘¸ì‹œì¸ì§€ í™•ì¸
                if self.first_push[split_name]:
                    # ì²˜ìŒì´ë©´ ìƒˆë¡œ ìƒì„±
                    dataset_dict.push_to_hub(
                        self.repo_id,
                        token=self.api.token,
                        private=True,
                        commit_message=f"Add {split_name} batch {batch_num}"
                    )
                    self.first_push[split_name] = False
                else:
                    # ì´í›„ëŠ” ì¶”ê°€ (appendëŠ” ìë™ìœ¼ë¡œ ë¨)
                    dataset_dict.push_to_hub(
                        self.repo_id,
                        token=self.api.token,
                        private=True,
                        commit_message=f"Add {split_name} batch {batch_num}"
                    )
                
                print(f"  âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ")
        
        finally:
            # 4. ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                print(f"  ğŸ§¹ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            
            # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
            import subprocess
            result = subprocess.run(['df', '-h', '/'], capture_output=True, text=True)
            lines = result.stdout.strip().split('\n')
            if len(lines) > 1:
                parts = lines[1].split()
                if len(parts) > 3:
                    print(f"  ğŸ’¾ ë‚¨ì€ ë””ìŠ¤í¬ ê³µê°„: {parts[3]}")
    
    def upload_split(self, zip_pairs: List[Tuple[str, str]], split_name: str, batch_size: int):
        """
        ì „ì²´ splitì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        """
        total_batches = (len(zip_pairs) + batch_size - 1) // batch_size
        
        for batch_num, batch_start in enumerate(range(0, len(zip_pairs), batch_size), 1):
            batch_end = min(batch_start + batch_size, len(zip_pairs))
            batch_pairs = zip_pairs[batch_start:batch_end]
            
            self.process_batch(batch_pairs, split_name, batch_num, total_batches)

def get_file_pairs(base_path: str, split: str) -> List[Tuple[str, str]]:
    """íŒŒì¼ ìŒ ëª©ë¡ ìƒì„±"""
    source_dir = os.path.join(base_path, split, "01.ì›ì²œë°ì´í„°")
    label_dir = os.path.join(base_path, split, "02.ë¼ë²¨ë§ë°ì´í„°")
    
    if split == "Training":
        source_prefix, label_prefix = "TS_", "TL_"
    else:
        source_prefix, label_prefix = "VS_", "VL_"
    
    pairs = []
    source_files = sorted([f for f in os.listdir(source_dir) if f.startswith(source_prefix) and f.endswith('.zip')])
    
    for source_file in source_files:
        base_name = source_file.replace(source_prefix, '')
        label_file = label_prefix + base_name
        
        source_path = os.path.join(source_dir, source_file)
        label_path = os.path.join(label_dir, label_file)
        
        if os.path.exists(label_path):
            pairs.append((source_path, label_path))
    
    return pairs

def main():
    parser = argparse.ArgumentParser(description="í•œêµ­ì–´ ìŒì„± ë°ì´í„° ë°°ì¹˜ ì—…ë¡œë“œ")
    parser.add_argument("--repo-id", required=True)
    parser.add_argument("--token", help="HuggingFace API token")
    parser.add_argument("--mode", choices=['test', 'validation', 'training', 'all'], default='test')
    parser.add_argument("--batch-size", type=int, default=5, help="ë°°ì¹˜ í¬ê¸°")
    
    args = parser.parse_args()
    
    base_path = "./132.ì—°ë ¹ëŒ€ë³„ íŠ¹ì§•ì  ë°œí™”(ì€ì–´Â·ì†ì–´ ë“±) ìŒì„± ë°ì´í„°/01-1.ì •ì‹ê°œë°©ë°ì´í„°"
    
    uploader = KoreanSpeechBatchUploader(args.repo_id, args.token)
    
    if args.mode == 'test':
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        val_pairs = get_file_pairs(base_path, "Validation")[:2]
        uploader.upload_split(val_pairs, 'validation', args.batch_size)
        
    elif args.mode == 'validation':
        print("ğŸ“Š Validation ë°ì´í„° ì²˜ë¦¬")
        val_pairs = get_file_pairs(base_path, "Validation")
        print(f"ì´ {len(val_pairs)}ê°œ íŒŒì¼")
        uploader.upload_split(val_pairs, 'validation', args.batch_size)
        
    elif args.mode == 'training':
        print("ğŸ“š Training ë°ì´í„° ì²˜ë¦¬")
        train_pairs = get_file_pairs(base_path, "Training")
        print(f"ì´ {len(train_pairs)}ê°œ íŒŒì¼")
        uploader.upload_split(train_pairs, 'train', args.batch_size)
        
    elif args.mode == 'all':
        print("ğŸŒŸ ì „ì²´ ë°ì´í„° ì²˜ë¦¬")
        
        # Validation
        val_pairs = get_file_pairs(base_path, "Validation")
        print(f"\nğŸ” Validation: {len(val_pairs)}ê°œ íŒŒì¼")
        uploader.upload_split(val_pairs, 'validation', args.batch_size)
        
        # Training
        train_pairs = get_file_pairs(base_path, "Training")
        print(f"\nğŸ“š Training: {len(train_pairs)}ê°œ íŒŒì¼")
        uploader.upload_split(train_pairs, 'train', args.batch_size)
        
        print(f"\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ”— https://huggingface.co/datasets/{args.repo_id}")

if __name__ == "__main__":
    main()