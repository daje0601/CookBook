#!/usr/bin/env python
# coding: utf-8
import pandas as pd 
from glob import glob
from pathlib import Path
from huggingface_hub import HfApi, create_repo
from datasets import Dataset, Audio, DatasetDict

data_path = "."
csv_path = Path(data_path) / "extracted_data.csv"

df = pd.read_csv(csv_path)
data_dir = Path(data_path)
source_folders = [item for item in data_dir.iterdir() 
                     if item.is_dir() and item.name.startswith('[ì›ì²œ]')]
len(source_folders), source_folders[-1]


all_files = []
for folder in source_folders:
    wav_files = list(folder.rglob("*.wav"))
    for wav_file in wav_files:
            all_files.append({
                'FileName': wav_file.name,
                'AudioPath': str(wav_file),
            })

source_df = pd.DataFrame(all_files)
merged_df = df.merge(source_df, on='FileName', how='left')

# ê²°ê³¼ í™•ì¸
print(f"Original df: {len(df):,}ê°œ")
print(f"Source df: {len(source_df):,}ê°œ") 
print(f"Merged df: {len(merged_df):,}ê°œ")

# ë§¤ì¹­ ê²°ê³¼
matched_count = merged_df['AudioPath'].notna().sum()
print(f"ë§¤ì¹­ëœ ë ˆì½”ë“œ: {matched_count:,}ê°œ")
print(f"ë§¤ì¹­ë¥ : {matched_count/len(merged_df)*100:.1f}%")

df = merged_df[merged_df['AudioPath'].notna()].copy()

print(f"ğŸ“Š {len(df):,}ê°œ ìƒ˜í”Œë¡œ ë°ì´í„°ì…‹ ìƒì„±")

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ
dataset_df = df[['LabelText', 'AudioPath', 'Gender', 'Age', 'Dialect']].copy()
dataset_df.columns = ['text', 'audio', 'gender', 'age', 'dialect']
dataset = Dataset.from_pandas(dataset_df)
dataset = dataset.cast_column("audio", Audio())

dataset_dict = DatasetDict({
    "validation": dataset
})

dataset.save_to_disk("./dataset_folder")
repo_id = "your_repo_id/your_dataset_name"
create_repo(repo_id, repo_type="dataset", private=True, exist_ok=True)

# ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì´ë ‡ê²Œ ì˜¬ë¦¬ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤. 
api = HfApi()

api.upload_large_folder(
    folder_path="./dataset_folder",
    repo_id=repo_id, 
    repo_type="dataset",
    private=True
)

print("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")

