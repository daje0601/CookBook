{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 암호화를 위해 dotenv를 활용 \n",
    "load_dotenv()\n",
    "huggingface_token = os.environ.get(\"HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트 설정 \n",
    "system_message = \"당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.\"\n",
    "\n",
    "# 실제로 사용자 입력 -> 모델이 답해야 하는 프롬프트\n",
    "prompt = \"\"\"입력 정보:\n",
    "- name: {name}\n",
    "- image: [image]\n",
    "\n",
    "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
    "1) gender\n",
    "2) masterCategory\n",
    "3) subCategory\n",
    "4) season\n",
    "5) usage\n",
    "6) baseColour\n",
    "7) articleType\n",
    "\n",
    "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
    "{{\n",
    "  \"gender\": \"예시값\",\n",
    "  \"masterCategory\": \"예시값\",\n",
    "  \"subCategory\": \"예시값\",\n",
    "  \"season\": \"예시값\",\n",
    "  \"usage\": \"예시값\",\n",
    "  \"baseColour\": \"예시값\",\n",
    "  \"articleType\": \"예시값\"\n",
    "}}\n",
    "\n",
    "# 예시\n",
    "{{\n",
    "  \"gender\": \"Men\",\n",
    "  \"masterCategory\": \"Accessories\",\n",
    "  \"subCategory\": \"Eyewear\",\n",
    "  \"season\": \"Winter\",\n",
    "  \"usage\": \"Casual\",\n",
    "  \"baseColour\": \"Blue\",\n",
    "  \"articleType\": \"Sunglasses\"\n",
    "}}\n",
    "\n",
    "# 주의\n",
    "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1c4ed884594b1592f6fd748c7af5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cace05c2cf3467eab015c3a03e77d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/221M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708b75e793954857ac5f8683e1c20609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeb5418663a4d2bb71d10e7c7b38e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# label을 생성하기 위한 함수 \n",
    "def combine_cols_to_label(example):\n",
    "    label_dict = {\n",
    "        \"gender\": example[\"gender\"],\n",
    "        \"masterCategory\": example[\"masterCategory\"],\n",
    "        \"subCategory\": example[\"subCategory\"],\n",
    "        \"season\": example[\"season\"],\n",
    "        \"usage\": example[\"usage\"],\n",
    "        \"baseColour\": example[\"baseColour\"],\n",
    "        \"articleType\": example[\"articleType\"],\n",
    "    }\n",
    "    example[\"label\"] = json.dumps(label_dict, ensure_ascii=False)\n",
    "    return example\n",
    "\n",
    "# 대화용 포맷으로 변환하는 함수 \n",
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_message\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        # 제품명 \n",
    "                        \"text\": prompt.format(name=sample[\"productDisplayName\"]),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        # 이미지 파일 \n",
    "                        \"image\": sample[\"file_path\"],  \n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        # combine_cols_to_label에서 만든 JSON 문자열\n",
    "                        \"text\": sample[\"label\"],\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 전처리한 데이터셋 불러오기 \n",
    "dataset = load_dataset(\"daje/kaggle-image-datasets\", split=\"train\")\n",
    "dataset_add_label = dataset.map(combine_cols_to_label)\n",
    "dataset_add_label = dataset_add_label.shuffle(seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80>,\n",
       " 'id': 44429,\n",
       " 'gender': 'Men',\n",
       " 'masterCategory': 'Footwear',\n",
       " 'subCategory': 'Shoes',\n",
       " 'articleType': 'Formal Shoes',\n",
       " 'baseColour': 'Black',\n",
       " 'season': 'Summer',\n",
       " 'year': '2013',\n",
       " 'usage': 'Formal',\n",
       " 'productDisplayName': 'Gliders Men Black Formal Shoes',\n",
       " 'label': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Shoes\", \"season\": \"Summer\", \"usage\": \"Formal\", \"baseColour\": \"Black\", \"articleType\": \"Formal Shoes\"}'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨을 추가한 데이터의 예시 \n",
    "dataset_add_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메세지 포맷으로 데이터셋 변환 \n",
    "formatted_dataset = [format_data(row) for row in dataset_add_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '입력 정보:\\n- name: Gliders Men Black Formal Shoes\\n- image: [image]\\n\\n위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\\n1) gender\\n2) masterCategory\\n3) subCategory\\n4) season\\n5) usage\\n6) baseColour\\n7) articleType\\n\\n출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\\n{\\n  \"gender\": \"예시값\",\\n  \"masterCategory\": \"예시값\",\\n  \"subCategory\": \"예시값\",\\n  \"season\": \"예시값\",\\n  \"usage\": \"예시값\",\\n  \"baseColour\": \"예시값\",\\n  \"articleType\": \"예시값\"\\n}\\n\\n# 예시\\n{\\n  \"gender\": \"Men\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Eyewear\",\\n  \"season\": \"Winter\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Blue\",\\n  \"articleType\": \"Sunglasses\"\\n}\\n\\n# 주의\\n- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\\n'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Shoes\", \"season\": \"Summer\", \"usage\": \"Formal\", \"baseColour\": \"Black\", \"articleType\": \"Formal Shoes\"}'}]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메세지 포맷으로 변환 데이터 예시 \n",
    "formatted_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size=0.1로 설정하여 전체 데이터의 10%를 테스트 세트로 분리\n",
    "train_dataset, test_dataset = train_test_split(formatted_dataset, \n",
    "                                             test_size=0.1, \n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39996, 4444)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset, test_dataset 데이터 수 확인 \n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a29a3c61d624a2a8e36155f7669ab56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e4f66823c6488aabadde4e050b2bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/56.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d528aff8c3e544b981b8dd2b607c2db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15414faa17b4414fafcd46384f9cb3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46db5c39625e4c1cb53ec4dcff4fa73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964527fbc7f43eebbf55f1e2260fe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b6812863ed4d4ba19e04651562aabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6136aed6c5c42c7bd63f2aca348e4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bcc929cadf48dcac94583f19ab22c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908f627d72d0406cacba7afd813108af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fba76dc3954ff1872dd8514570b33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c931c239bad9473fbef71d009d83907c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9875b191564875b31a852a852d84e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44e99be172f46aba44056bdca6eff4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f418b343edf6403c9fded85b1929cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61218f1662b4f0f9ad83483c4074497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2-VL-7B-Instruct\" \n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"auto\",                            # GPU 메모리에 자동 할당\n",
    "   torch_dtype=torch.bfloat16,                   # bfloat16 정밀도 사용\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)  # 텍스트/이미지 전처리기 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "입력 정보:\n",
      "- name: Myntra Women's I Want You Black T-shirt\n",
      "- image: [image]\n",
      "\n",
      "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
      "1) gender\n",
      "2) masterCategory\n",
      "3) subCategory\n",
      "4) season\n",
      "5) usage\n",
      "6) baseColour\n",
      "7) articleType\n",
      "\n",
      "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
      "{\n",
      "  \"gender\": \"예시값\",\n",
      "  \"masterCategory\": \"예시값\",\n",
      "  \"subCategory\": \"예시값\",\n",
      "  \"season\": \"예시값\",\n",
      "  \"usage\": \"예시값\",\n",
      "  \"baseColour\": \"예시값\",\n",
      "  \"articleType\": \"예시값\"\n",
      "}\n",
      "\n",
      "# 예시\n",
      "{\n",
      "  \"gender\": \"Men\",\n",
      "  \"masterCategory\": \"Accessories\",\n",
      "  \"subCategory\": \"Eyewear\",\n",
      "  \"season\": \"Winter\",\n",
      "  \"usage\": \"Casual\",\n",
      "  \"baseColour\": \"Blue\",\n",
      "  \"articleType\": \"Sunglasses\"\n",
      "}\n",
      "\n",
      "# 주의\n",
      "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
      "<|vision_start|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"gender\": \"Women\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Topwear\", \"season\": \"Summer\", \"usage\": \"Casual\", \"baseColour\": \"Black\", \"articleType\": \"Tshirts\"}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    train_dataset[2][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "#############################################\n",
    "# \"배치 추론\"용 함수\n",
    "#############################################\n",
    "def generate_batch_description(batch_messages, model, processor):\n",
    "    # 배치 전체의 text / images / videos를 한번에 준비\n",
    "    texts = []\n",
    "    all_image_inputs = []\n",
    "    all_video_inputs = []\n",
    "\n",
    "    # (A) 각 샘플마다 QWen-VL용 텍스트 생성 + 이미지/비디오 추출\n",
    "    for messages in batch_messages:\n",
    "        # 1) QWen-VL 텍스트 템플릿 생성\n",
    "        text_prompt = processor.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        texts.append(text_prompt)\n",
    "\n",
    "        # 2) 이미지/비디오 추출\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "        # 비디오가 없는 경우가 대부분이면, video_inputs를 무조건 None으로 처리해도 됨.\n",
    "        all_image_inputs.append(image_inputs[0] if image_inputs else None)\n",
    "        all_video_inputs.append(video_inputs[0] if video_inputs else None)\n",
    "\n",
    "    # (B) 비디오가 전혀 없으면 videos=None으로 넘기도록 처리\n",
    "    if any(x is not None for x in all_video_inputs):\n",
    "        videos_to_pass = all_video_inputs\n",
    "    else:\n",
    "        videos_to_pass = None  \n",
    "\n",
    "    # (C) processor로 배치 전체 인코딩\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=all_image_inputs if any(x is not None for x in all_image_inputs) else None,\n",
    "        videos=videos_to_pass,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    # (D) 모델 추론\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            top_p=1.0,\n",
    "            do_sample=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "    # (E) 디코딩\n",
    "    batch_outputs = []\n",
    "    for i, out_ids in enumerate(generated_ids):\n",
    "        prompt_len = len(inputs.input_ids[i])\n",
    "        trimmed_out_ids = out_ids[prompt_len:]\n",
    "        decoded = processor.decode(\n",
    "            trimmed_out_ids,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        batch_outputs.append(decoded)\n",
    "\n",
    "    return batch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaeb8c36fea400b9d1fe2697550fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "before_results = []\n",
    "batch_size = 128\n",
    "\n",
    "# 배치단위로 for문을 돌면서 generate_batch_description함수를 이용하여 인퍼런스를 진행합니다. \n",
    "for start_idx in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch_data = test_dataset[start_idx : start_idx + batch_size]\n",
    "\n",
    "    batch_messages = []\n",
    "    answers = []  # 각 샘플 정답\n",
    "    for item in batch_data:\n",
    "        # system+user 메시지\n",
    "        sys_usr = item[\"messages\"][:2]\n",
    "        batch_messages.append(sys_usr)\n",
    "\n",
    "        # 정답(assistant)\n",
    "        ans_text = item[\"messages\"][2][\"content\"][0][\"text\"]\n",
    "        answers.append(ans_text)\n",
    "\n",
    "    # 한 번에 모델 추론\n",
    "    predicted_texts = generate_batch_description(batch_messages, model, processor)\n",
    "\n",
    "    # 결과 저장\n",
    "    for ans, pred in zip(answers, predicted_texts):\n",
    "        before_results.append((ans, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"gender\": \"Women\", \"masterCategory\": \"Accessories\", \"subCategory\": \"Jewellery\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Black\", \"articleType\": \"Necklace and Chains\"}',\n",
       " '{\\n  \"gender\": \"Women\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Jewelry\",\\n  \"season\": \"Any\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Black\",\\n  \"articleType\": \"Necklace\"\\n}')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"gender\": \"Women\", \"masterCategory\": \"Accessories\", \"subCategory\": \"Jewellery\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Black\", \"articleType\": \"Necklace and Chains\"}\n",
      "{\"gender\": \"Women\", \"masterCategory\": \"Accessories\", \"subCategory\": \"Jewelry\", \"season\": \"Any\", \"usage\": \"Casual\", \"baseColour\": \"Black\", \"articleType\": \"Necklace\"}\n"
     ]
    }
   ],
   "source": [
    "import json_repair\n",
    "print(json_repair.repair_json(before_results[0][0]))\n",
    "print(json_repair.repair_json(before_results[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_repair.repair_json(before_results[0][0]) == json_repair.repair_json(before_results[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy 계산\n",
    "\n",
    "correct_count = sum(1 for (ans, pred) in before_results if json_repair.repair_json(ans) == json_repair.repair_json(pred))\n",
    "accuracy = correct_count / len(before_results) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_json_results = [(json_repair.repair_json(ans, return_objects=True), json_repair.repair_json(pred, return_objects=True)) for (ans, pred) in before_results]\n",
    "before_answers = [ans for (ans, pred) in before_json_results]\n",
    "before_predicts = [pred for (ans, pred) in before_json_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gender': 'Women',\n",
       "  'masterCategory': 'Accessories',\n",
       "  'subCategory': 'Jewellery',\n",
       "  'season': 'Fall',\n",
       "  'usage': 'Casual',\n",
       "  'baseColour': 'Black',\n",
       "  'articleType': 'Necklace and Chains'},\n",
       " {'gender': 'Women',\n",
       "  'masterCategory': 'Accessories',\n",
       "  'subCategory': 'Jewelry',\n",
       "  'season': 'Any',\n",
       "  'usage': 'Casual',\n",
       "  'baseColour': 'Black',\n",
       "  'articleType': 'Necklace'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_answers[0], before_predicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field Accuracy (Micro):50.32%\n",
      "Field Accuracy (Macro):50.32%\n"
     ]
    }
   ],
   "source": [
    "# (Micro) 방식으로 전체 필드를 한꺼번에 세어 정확도(Accuracy) 구하는 함수 \n",
    "def field_accuracy_micro(y_true_list, y_pred_list):\n",
    "\n",
    "    total_matched = 0\n",
    "    total_fields = 0\n",
    "    \n",
    "    for dtrue, dpred in zip(y_true_list, y_pred_list):\n",
    "        for key in dtrue.keys():\n",
    "            total_fields += 1\n",
    "            if key in dpred and dtrue[key] == dpred[key]:\n",
    "                total_matched += 1\n",
    "    \n",
    "    # 분모가 0인 경우(비어 있는 dict 등)를 대비\n",
    "    return total_matched / total_fields if total_fields > 0 else 0\n",
    "\n",
    "# (Macro) 방식으로 각 샘플별 Accuracy를 구한 뒤 평균 구하는 함수 \n",
    "def field_accuracy_macro(y_true_list, y_pred_list):\n",
    "    \n",
    "    acc_list = []\n",
    "    for dtrue, dpred in zip(y_true_list, y_pred_list):\n",
    "        matched = 0\n",
    "        total = len(dtrue.keys())  \n",
    "        for key in dtrue.keys():\n",
    "            if key in dpred and dtrue[key] == dpred[key]:\n",
    "                matched += 1\n",
    "        \n",
    "        acc = matched / total if total > 0 else 0\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    # 모든 샘플에 대한 Accuracy의 평균\n",
    "    return sum(acc_list) / len(acc_list) if len(acc_list) > 0 else 0\n",
    "\n",
    "\n",
    "# 전체 필드를 한꺼번에 세는 방식 (Micro)\n",
    "print(f\"Field Accuracy (Micro):{field_accuracy_micro(before_answers, before_predicts)*100:.2f}%\")\n",
    "\n",
    "# 샘플별 Accuracy를 구한 뒤 평균 (Macro)\n",
    "print(f\"Field Accuracy (Macro):{field_accuracy_macro(before_answers, before_predicts)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Scores(Precision) : 51.57%\n",
      "Micro Scores(Recall) : 50.32%\n",
      "Micro Scores(F1)  50.94%\n",
      "Macro Scores(Precision) : 50.32%\n",
      "Macro Scores(Recall) : 50.32%\n",
      "Macro Scores(F1)  50.32%\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1 구하는 함수 \n",
    "## (Micro) 방식으로 전체 필드를 한꺼번에 세어 정확도(Accuracy)를 구하는 함수 \n",
    "def dict_set_scores_micro(y_true_list, y_pred_list):\n",
    "\n",
    "    total_true_pairs = 0\n",
    "    total_pred_pairs = 0\n",
    "    total_intersect_pairs = 0\n",
    "    \n",
    "    for dtrue, dpred in zip(y_true_list, y_pred_list):\n",
    "        # 1) 만약 빈 문자열 \"\" 이거나 None이라면, 빈 dict로 처리\n",
    "        if isinstance(dpred, str) and dpred.strip() == \"\":\n",
    "            dpred = {}\n",
    "        if dpred is None:\n",
    "            dpred = {}\n",
    "        \n",
    "        # 필요하다면 y_true도 동일하게 처리 (빈 문자열일 수 있다면)\n",
    "        if isinstance(dtrue, str) and dtrue.strip() == \"\":\n",
    "            dtrue = {}\n",
    "        if dtrue is None:\n",
    "            dtrue = {}\n",
    "        \n",
    "        # 2) (key, value) 쌍 집합 만들기\n",
    "        true_pairs = set(dtrue.items())\n",
    "        pred_pairs = set(dpred.items())\n",
    "        \n",
    "        intersection = true_pairs.intersection(pred_pairs)\n",
    "        \n",
    "        total_true_pairs += len(true_pairs)\n",
    "        total_pred_pairs += len(pred_pairs)\n",
    "        total_intersect_pairs += len(intersection)\n",
    "    \n",
    "    precision = total_intersect_pairs / total_pred_pairs if total_pred_pairs else 0\n",
    "    recall = total_intersect_pairs / total_true_pairs if total_true_pairs else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "scores_micro = dict_set_scores_micro(before_answers, before_predicts)\n",
    "print(f'Micro Scores(Precision) : {scores_micro[\"precision\"]*100:.2f}%')\n",
    "print(f'Micro Scores(Recall) : {scores_micro[\"recall\"]*100:.2f}%')\n",
    "print(f'Micro Scores(F1)  {scores_micro[\"f1\"]*100:.2f}%')\n",
    "\n",
    "\n",
    "## 샘플별로 (k,v) 쌍 집합 Precision, Recall, F1을 구하고, 그걸 다시 평균(Macro) 구하는 함수 \n",
    "def dict_set_scores_macro(y_true_list, y_pred_list):\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    \n",
    "    for dtrue, dpred in zip(y_true_list, y_pred_list):\n",
    "        # 1) 만약 빈 문자열 \"\" 이거나 None이라면, 빈 dict로 처리\n",
    "        if isinstance(dpred, str) and dpred.strip() == \"\":\n",
    "            dpred = {}\n",
    "        if dpred is None:\n",
    "            dpred = {}\n",
    "        \n",
    "        # 필요하다면 y_true도 동일하게 처리 (빈 문자열일 수 있다면)\n",
    "        if isinstance(dtrue, str) and dtrue.strip() == \"\":\n",
    "            dtrue = {}\n",
    "        if dtrue is None:\n",
    "            dtrue = {}\n",
    "        \n",
    "        # 2) (key, value) 쌍 집합 만들기\n",
    "        true_pairs = set(dtrue.items())\n",
    "        pred_pairs = set(dpred.items())\n",
    "        \n",
    "        # 3) 교집합 크기\n",
    "        intersection = true_pairs.intersection(pred_pairs)\n",
    "        \n",
    "        # 4) Precision, Recall, F1\n",
    "        precision = len(intersection) / len(pred_pairs) if len(pred_pairs) > 0 else 0\n",
    "        recall = len(intersection) / len(true_pairs) if len(true_pairs) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # 5) 리스트에 저장\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    # 6) 모든 샘플의 평균(Macro)\n",
    "    n = len(precisions)  # = len(y_true_list) = len(y_pred_list)\n",
    "    avg_precision = sum(precisions) / n if n > 0 else 0\n",
    "    avg_recall = sum(recalls) / n if n > 0 else 0\n",
    "    avg_f1 = sum(f1s) / n if n > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": avg_precision,\n",
    "        \"recall\": avg_recall,\n",
    "        \"f1\": avg_f1\n",
    "    }\n",
    "\n",
    "scores_macro = dict_set_scores_macro(before_answers, before_predicts)\n",
    "print(f'Macro Scores(Precision) : {scores_macro[\"precision\"]*100:.2f}%')\n",
    "print(f'Macro Scores(Recall) : {scores_macro[\"recall\"]*100:.2f}%')\n",
    "print(f'Macro Scores(F1)  {scores_macro[\"f1\"]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Gender accuracy: 97.00%\n",
      "masterCategory accuracy: 37.58%\n",
      "subCategory accuracy: 16.88%\n",
      "articleType accuracy: 19.35%\n",
      "season accuracy: 30.02%\n",
      "usage accuracy: 76.87%\n",
      "baseColour accuracy: 83.26%\n"
     ]
    }
   ],
   "source": [
    "def to_dict_if_str(obj):\n",
    "    \"\"\"\n",
    "    obj가 str이면 JSON으로 로드하고,\n",
    "    이미 dict 등의 타입이면 그대로 반환.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, str):\n",
    "        try:\n",
    "            return json.loads(obj)\n",
    "        except json.JSONDecodeError:\n",
    "            # json.loads()가 실패하면 json_repair로 한 번 더 시도\n",
    "            return json_repair.repair_json(obj, return_objects=True)\n",
    "    return obj\n",
    "\n",
    "def compute_field_accuracy(predictions, targets, field):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for pred, target in zip(predictions, targets):\n",
    "        # 문자열(JSON)인지 확인 후 dict로 변환\n",
    "        pred_dict = to_dict_if_str(pred)\n",
    "        target_dict = to_dict_if_str(target)\n",
    "        \n",
    "        if not isinstance(pred_dict, dict) or not isinstance(target_dict, dict):\n",
    "            continue\n",
    "        \n",
    "        if field in pred_dict and field in target_dict:\n",
    "            total += 1\n",
    "            if pred_dict[field] == target_dict[field]:\n",
    "                correct += 1\n",
    "    \n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "import json_repair\n",
    "before_json_results = [(json_repair.repair_json(ans, return_objects=True), json_repair.repair_json(pred, return_objects=True)) for (ans, pred) in before_results]\n",
    "before_answers = [ans for (ans, pred) in before_json_results]\n",
    "before_predicts = [pred for (ans, pred) in before_json_results]\n",
    "\n",
    "# 특정 필드별 정확도\n",
    "gender_accuracy = compute_field_accuracy(before_predicts, before_answers, 'gender')\n",
    "print(f\"Gender accuracy: {gender_accuracy:.2%}\")\n",
    "masterCategory_accuracy = compute_field_accuracy(before_predicts, before_answers, 'masterCategory')\n",
    "print(f\"masterCategory accuracy: {masterCategory_accuracy:.2%}\")\n",
    "subCategory_accuracy = compute_field_accuracy(before_predicts, before_answers, 'subCategory')\n",
    "print(f\"subCategory accuracy: {subCategory_accuracy:.2%}\")\n",
    "articleType_accuracy = compute_field_accuracy(before_predicts, before_answers, 'articleType')\n",
    "print(f\"articleType accuracy: {articleType_accuracy:.2%}\")\n",
    "season_accuracy = compute_field_accuracy(before_predicts, before_answers, 'season')\n",
    "print(f\"season accuracy: {season_accuracy:.2%}\")\n",
    "usage_accuracy = compute_field_accuracy(before_predicts, before_answers, 'usage')\n",
    "print(f\"usage accuracy: {usage_accuracy:.2%}\")\n",
    "baseColour_accuracy = compute_field_accuracy(before_predicts, before_answers, 'baseColour')\n",
    "print(f\"baseColour accuracy: {baseColour_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
